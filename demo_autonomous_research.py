"""
Autonomous Research Capabilities Demo
Demonstrates Penny's ability to identify knowledge gaps, conduct research,
synthesize findings, and generate actionable insights
"""

import asyncio
from datetime import datetime

from autonomous_research_tool_server import create_autonomous_research_server


async def demo_autonomous_research_scenarios():
    """Demonstrate autonomous research in realistic scenarios"""
    print("üî¨ AUTONOMOUS RESEARCH CAPABILITIES DEMO")
    print("=" * 60)
    print("Demonstrating how Penny can identify knowledge gaps during")
    print("conversations, conduct independent research, and synthesize")
    print("actionable insights for continuous learning.\n")

    server = await create_autonomous_research_server()

    try:
        scenarios = [
            {
                "title": "üìö SCENARIO 1: Learning New Technology",
                "context": "User is asking about building a modern web application",
                "conversation": "I want to build a web app but I'm not sure about the latest frontend frameworks. React, Vue, Angular - which one should I choose? I don't know what the current best practices are.",
                "user_query": "What's the best frontend framework for 2024? I'm not familiar with the latest developments."
            },
            {
                "title": "ü§ñ SCENARIO 2: AI/ML Knowledge Gap",
                "context": "User working on machine learning project",
                "conversation": "I'm working on a computer vision project but I'm not sure about the latest models. I've heard about transformers for vision but don't know how they work compared to CNNs.",
                "user_query": "How do vision transformers compare to CNNs? I need to understand the current state of computer vision."
            },
            {
                "title": "üõ°Ô∏è SCENARIO 3: Security Best Practices",
                "context": "User building a production system",
                "conversation": "I'm deploying my app to production but I'm not sure about security best practices. What should I know about authentication, authorization, and data protection?",
                "user_query": "What are the essential security practices I need to implement before going live?"
            },
            {
                "title": "üöÄ SCENARIO 4: DevOps and Deployment",
                "context": "User transitioning to cloud deployment",
                "conversation": "I've been developing locally but now I need to deploy to the cloud. I'm not familiar with containerization, CI/CD, or cloud platforms.",
                "user_query": "How do I set up a proper deployment pipeline? I don't know where to start with DevOps."
            },
            {
                "title": "üìä SCENARIO 5: Data Science Methodology",
                "context": "User starting data science project",
                "conversation": "I have a dataset and want to build a predictive model. I'm not sure about the latest feature engineering techniques or model selection strategies.",
                "user_query": "What's the current best practice workflow for building predictive models? I'm not up to date with modern data science."
            }
        ]

        successful_scenarios = 0
        total_insights = 0
        total_recommendations = 0

        for i, scenario in enumerate(scenarios, 1):
            print(f"\n{scenario['title']}")
            print("-" * 50)
            print(f"üéØ Context: {scenario['context']}")
            print(f"üí¨ User Query: {scenario['user_query'][:80]}...")

            try:
                # Step 1: Knowledge Gap Detection
                print("\nüìç Step 1: Detecting Knowledge Gaps")
                gap_result = await server.identify_knowledge_gaps(
                    conversation_context=scenario['conversation'],
                    user_query=scenario['user_query'],
                    confidence_threshold=0.6,
                    user_id=f"demo_user_{i}"
                )

                if gap_result.success:
                    gaps = gap_result.data["knowledge_gaps"]
                    print(f"   ‚úÖ Knowledge gaps identified: {len(gaps)}")

                    if gaps:
                        primary_gap = gaps[0]
                        print(f"   üéØ Primary gap: {primary_gap['gap_type']} - {primary_gap['description'][:60]}...")
                        print(f"   üéØ Confidence: {primary_gap['confidence']:.1f}")

                        # Step 2: Research Question Generation
                        print("\n‚ùì Step 2: Generating Research Questions")
                        question_result = await server.generate_research_questions(
                            knowledge_gap=primary_gap,
                            max_questions=3,
                            user_id=f"demo_user_{i}"
                        )

                        if question_result.success:
                            questions = question_result.data["research_questions"]
                            print(f"   ‚úÖ Research questions generated: {len(questions)}")
                            for j, q in enumerate(questions, 1):
                                print(f"   Q{j}: {q['question']}")

                            # Step 3: Research Plan Creation
                            print("\nüìã Step 3: Creating Research Plan")
                            plan_result = await server.create_research_plan(
                                knowledge_gap=primary_gap,
                                research_scope="comprehensive",
                                time_limit=180,
                                user_id=f"demo_user_{i}"
                            )

                            if plan_result.success:
                                plan = plan_result.data["research_plan"]
                                print(f"   ‚úÖ Research plan created: {plan['plan_id']}")
                                print(f"   ‚è±Ô∏è Estimated time: {plan_result.data['estimated_time']} seconds")
                                print(f"   üìù Questions to research: {plan_result.data['question_count']}")

                                # Step 4: Research Execution
                                print("\nüî¨ Step 4: Executing Research")
                                execution_result = await server.execute_research_plan(
                                    research_plan=plan,
                                    user_id=f"demo_user_{i}"
                                )

                                if execution_result.success:
                                    findings = execution_result.data["research_findings"]
                                    print(f"   ‚úÖ Research completed in {execution_result.data['execution_time']:.2f}s")
                                    print(f"   üìä Findings generated: {len(findings)}")

                                    # Step 5: Information Synthesis
                                    print("\nüß† Step 5: Synthesizing Research Findings")
                                    synthesis_result = await server.synthesize_research_findings(
                                        research_findings=findings,
                                        synthesis_style="comprehensive",
                                        user_id=f"demo_user_{i}"
                                    )

                                    if synthesis_result.success:
                                        synthesis = synthesis_result.data
                                        print(f"   ‚úÖ Research synthesis complete")
                                        print(f"   üí° Key insights: {len(synthesis['key_insights'])}")
                                        print(f"   üéØ Recommendations: {len(synthesis['recommendations'])}")
                                        print(f"   üìà Confidence level: {synthesis['confidence']:.2f}")
                                        print(f"   üîó Related topics: {len(synthesis['related_topics'])}")

                                        total_insights += len(synthesis['key_insights'])
                                        total_recommendations += len(synthesis['recommendations'])

                                        # Show sample insights
                                        if synthesis['key_insights']:
                                            print(f"   üí° Sample insight: {synthesis['key_insights'][0][:80]}...")

                                        if synthesis['recommendations']:
                                            print(f"   üéØ Sample recommendation: {synthesis['recommendations'][0][:80]}...")

                                        # Step 6: Knowledge Storage
                                        print("\nüíæ Step 6: Storing Research Findings")
                                        storage_result = await server.store_research_findings(
                                            insights={
                                                "scenario": scenario['title'],
                                                "synthesis": synthesis
                                            },
                                            knowledge_category=f"scenario_{i}_knowledge",
                                            confidence_level=synthesis['confidence'],
                                            user_id=f"demo_user_{i}"
                                        )

                                        if storage_result.success:
                                            print(f"   ‚úÖ Knowledge stored in knowledge base")
                                            print(f"   üìö Knowledge base size: {storage_result.data['knowledge_base_size']}")

                                        print("\nüéâ Autonomous Research Cycle Complete!")
                                        successful_scenarios += 1

                                    else:
                                        print(f"   ‚ùå Synthesis failed: {synthesis_result.error}")
                                else:
                                    print(f"   ‚ùå Research execution failed: {execution_result.error}")
                            else:
                                print(f"   ‚ùå Plan creation failed: {plan_result.error}")
                        else:
                            print(f"   ‚ùå Question generation failed: {question_result.error}")
                    else:
                        print(f"   ‚ö†Ô∏è No gaps found with sufficient confidence")
                else:
                    print(f"   ‚ùå Gap detection failed: {gap_result.error}")

            except Exception as e:
                print(f"\n‚ùå Scenario failed: {e}")

        # Overall Results
        print("\n" + "=" * 60)
        print("üéä AUTONOMOUS RESEARCH DEMONSTRATION COMPLETE")
        print("=" * 60)

        success_rate = (successful_scenarios / len(scenarios)) * 100

        print(f"\nüìä RESEARCH OUTCOMES:")
        print(f"   Scenarios completed: {successful_scenarios}/{len(scenarios)}")
        print(f"   Success rate: {success_rate:.1f}%")
        print(f"   Total insights generated: {total_insights}")
        print(f"   Total recommendations: {total_recommendations}")

        # Get server metrics
        metrics = await server.get_performance_metrics()
        print(f"   Knowledge gaps identified: {metrics['total_knowledge_gaps_identified']}")
        print(f"   Research questions generated: {metrics['total_research_questions_generated']}")
        print(f"   Research sessions: {metrics['total_research_sessions']}")
        print(f"   Knowledge base entries: {metrics['knowledge_base_size']}")

        print(f"\nüß† AUTONOMOUS RESEARCH CAPABILITIES VALIDATED:")
        print("‚úÖ Real-time knowledge gap detection during conversations")
        print("‚úÖ Intelligent research question generation from gaps")
        print("‚úÖ Comprehensive research planning and execution")
        print("‚úÖ Multi-source information synthesis and insight generation")
        print("‚úÖ Actionable recommendation creation from research")
        print("‚úÖ Persistent knowledge storage for continuous learning")
        print("‚úÖ Security-validated research operations with rate limiting")
        print("‚úÖ Performance monitoring and metrics collection")

        print(f"\nüöÄ PENNY'S AUTONOMOUS LEARNING FOUNDATION:")
        print("‚Ä¢ Identifies what she doesn't know during natural conversations")
        print("‚Ä¢ Automatically generates focused research questions")
        print("‚Ä¢ Conducts independent research using available sources")
        print("‚Ä¢ Synthesizes findings into coherent insights and recommendations")
        print("‚Ä¢ Stores knowledge for future conversations and reference")
        print("‚Ä¢ Operates within security boundaries with human oversight")
        print("‚Ä¢ Demonstrates continuous learning and knowledge accumulation")

        if success_rate >= 80:
            print(f"\nüéâ AUTONOMOUS RESEARCH SYSTEM OPERATIONAL!")
            print("Ready to enable Penny's self-directed learning capabilities")
        else:
            print(f"\n‚ö†Ô∏è Some autonomous research features need refinement")

        return success_rate >= 80

    finally:
        await server.stop()


async def demo_specific_research_capabilities():
    """Demonstrate specific autonomous research capabilities"""
    print("\nüî¨ SPECIFIC AUTONOMOUS RESEARCH CAPABILITIES")
    print("=" * 50)

    server = await create_autonomous_research_server()

    try:
        # Demo 1: Multi-Gap Detection
        print("\n1Ô∏è‚É£ MULTI-GAP DETECTION IN COMPLEX CONVERSATIONS")

        complex_conversation = """
        User: I'm building a microservices architecture but I'm struggling with several things.
        Assistant: I'd be happy to help! What specific aspects are you finding challenging?
        User: Well, I don't know how to handle service discovery, I'm not sure about the best API gateway solutions, and I'm uncertain about database patterns for microservices. Also, how do I monitor everything?
        Assistant: Those are all important considerations. Let me research these topics to give you current best practices.
        """

        analysis_result = await server.analyze_conversation_for_learning_opportunities(
            conversation_history=complex_conversation,
            max_gaps=6,
            user_id="multi_gap_demo"
        )

        if analysis_result.success:
            opportunities = analysis_result.data["learning_opportunities"]
            print(f"   ‚úÖ Multiple learning opportunities detected: {len(opportunities)}")
            for i, opp in enumerate(opportunities[:3], 1):
                print(f"   Gap {i}: {opp['gap_type']} - {opp['description'][:60]}...")

        # Demo 2: Research Quality Assessment
        print("\n2Ô∏è‚É£ RESEARCH QUALITY ASSESSMENT AND VALIDATION")

        quality_data = {
            "sources": [
                {"credibility_score": 0.95, "content_length": 2000},  # High quality
                {"credibility_score": 0.45, "content_length": 300},   # Low quality
                {"credibility_score": 0.85, "content_length": 1500},  # Good quality
                {"credibility_score": 0.92, "content_length": 1800},  # High quality
            ]
        }

        quality_result = await server.validate_information_quality(
            source_data=quality_data,
            credibility_threshold=0.8,
            user_id="quality_demo"
        )

        if quality_result.success:
            validation = quality_result.data
            print(f"   ‚úÖ Quality assessment complete")
            print(f"   üìä Total sources evaluated: {validation['total_sources']}")
            print(f"   ‚≠ê High-quality sources: {validation['high_quality_sources']}")
            print(f"   üìà Quality percentage: {validation['quality_percentage']:.1f}%")

        # Demo 3: Advanced Insight Extraction
        print("\n3Ô∏è‚É£ ADVANCED INSIGHT EXTRACTION AND SYNTHESIS")

        research_data = {
            "content": "Machine learning deployment faces several critical challenges. Model versioning is essential for production ML systems. Data drift detection helps maintain model performance over time. A/B testing frameworks are crucial for validating model improvements. MLOps practices significantly reduce time-to-deployment for ML models.",
            "findings": [
                {
                    "key_insights": [
                        "MLOps practices reduce deployment time by 60%",
                        "Data drift affects 80% of production ML models",
                        "Model versioning is critical for rollback capabilities"
                    ]
                }
            ]
        }

        insight_result = await server.extract_key_insights(
            research_data=research_data,
            focus_areas=["deployment", "MLOps", "production"],
            user_id="insight_demo"
        )

        if insight_result.success:
            insights = insight_result.data["key_insights"]
            print(f"   ‚úÖ Advanced insights extracted: {len(insights)}")
            for i, insight in enumerate(insights[:3], 1):
                print(f"   Insight {i}: {insight[:70]}...")

        # Demo 4: Knowledge Base Integration
        print("\n4Ô∏è‚É£ KNOWLEDGE BASE INTEGRATION AND RETRIEVAL")

        knowledge_entries = [
            {
                "category": "ml_deployment",
                "insights": {"models": "containerization", "monitoring": "drift_detection"},
                "confidence": 0.88
            },
            {
                "category": "microservices",
                "insights": {"discovery": "consul", "gateway": "kong"},
                "confidence": 0.92
            },
            {
                "category": "security",
                "insights": {"auth": "oauth2", "encryption": "tls13"},
                "confidence": 0.85
            }
        ]

        stored_count = 0
        for entry in knowledge_entries:
            storage_result = await server.store_research_findings(
                insights=entry["insights"],
                knowledge_category=entry["category"],
                confidence_level=entry["confidence"],
                user_id="knowledge_demo"
            )
            if storage_result.success:
                stored_count += 1

        print(f"   ‚úÖ Knowledge entries stored: {stored_count}/{len(knowledge_entries)}")

        # Get final metrics
        metrics = await server.get_performance_metrics()
        print(f"   üìö Total knowledge base size: {metrics['knowledge_base_size']}")

        print(f"\nüéØ ADVANCED RESEARCH CAPABILITIES DEMONSTRATED:")
        print("   ‚Ä¢ Multi-dimensional knowledge gap detection")
        print("   ‚Ä¢ Source credibility assessment and quality validation")
        print("   ‚Ä¢ Context-aware insight extraction with focus areas")
        print("   ‚Ä¢ Structured knowledge storage and organization")
        print("   ‚Ä¢ Cross-session knowledge persistence and retrieval")
        print("   ‚Ä¢ Performance monitoring and capability assessment")

    finally:
        await server.stop()


if __name__ == "__main__":
    async def main():
        success = await demo_autonomous_research_scenarios()
        await demo_specific_research_capabilities()
        return success

    # Run the demonstration
    import sys
    success = asyncio.run(main())

    if success:
        print("\nüéä Autonomous Research Capabilities ready for deployment!")
        print("Penny can now identify knowledge gaps, conduct research, and learn autonomously.")
    else:
        print("\n‚ö†Ô∏è Issues found during autonomous research demonstration")

    sys.exit(0 if success else 1)